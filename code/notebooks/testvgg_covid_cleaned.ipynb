{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../util')\n",
    "from pocovid_dataset import PocovidDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PocovidDataset(root_dir='../data/image_dataset',\n",
    "                                     transform=transforms.Compose([\n",
    "                                       transforms.Resize((224,224)),\n",
    "                                       transforms.RandomAffine(10,translate=(0.1,0.1)),\n",
    "                                       transforms.ToTensor()\n",
    "                                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models/vgg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "class VGG16_model_2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: tuple = (3, 224, 224),\n",
    "                 hidden_size: int = 64,\n",
    "                 dropout: float = 0.5,\n",
    "                 num_classes: int = 3,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize a new network\n",
    "        \n",
    "        Inputs: \n",
    "        - input_size: Tuple, size of input data\n",
    "        - hidden_size: Integer, number of units to use in hidden layer\n",
    "        - dropout: Float, dropout coefficient\n",
    "        - num_classes: Integer, number of classes\n",
    "        \"\"\"\n",
    "        \n",
    "        super(VGG16_model_2, self).__init__()\n",
    "        \n",
    "        # load the VGG16 network\n",
    "        self.model = models.vgg16(pretrained=True)\n",
    "\n",
    "        # freeze weights of base model except last cnn layer\n",
    "        # model.parameters() does not include max pooling layers\n",
    "        last_frozen = 25\n",
    "        count = 0\n",
    "        for param in self.model.parameters():\n",
    "            count += 1\n",
    "            if count < last_frozen:\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        # Taking only sequential part\n",
    "        self.model = self.model.features\n",
    "    \n",
    "        self.avgpool = nn.AvgPool2d(4)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512, hidden_size)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn(x) \n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "        AvgPool2d-32            [-1, 512, 1, 1]               0\n",
      "          Flatten-33                  [-1, 512]               0\n",
      "           Linear-34                   [-1, 64]          32,832\n",
      "      BatchNorm1d-35                   [-1, 64]             128\n",
      "             ReLU-36                   [-1, 64]               0\n",
      "          Dropout-37                   [-1, 64]               0\n",
      "           Linear-38                    [-1, 3]             195\n",
      "================================================================\n",
      "Total params: 14,747,843\n",
      "Trainable params: 2,392,963\n",
      "Non-trainable params: 12,354,880\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.40\n",
      "Params size (MB): 56.26\n",
      "Estimated Total Size (MB): 275.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_2 = VGG16_model_2(input_size = (3,224,224), num_classes = 3)\n",
    "model_2.to(device)\n",
    "\n",
    "summary(model_2, (3,224,224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,747,843 total parameters.\n",
      "2,392,963 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_2.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model_2.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Pocovidnet Model has the following trainable/nontrain parameters:\n",
    "\n",
    "Total:         14,747,971\n",
    "\n",
    "Trainable:      2,392,963\n",
    "\n",
    "Non trainable: 12,355,008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Potential reason\n",
    "\n",
    "I am able to replicate everything except Batchnorm\n",
    "And I searched the reason for that. I found that Keras and Pytorch have a slight difference between the running means of batchnorm\n",
    "Which makes the no of parameters in them differ by half. Actually the no of trainable parameters are same\n",
    "Keras overcounts some hidden parameters as trainable which are not changed during backpropagation\n",
    "So, I think we are good\n",
    "There is a way to avoid that by manually setting the torch settings to replicate Keras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
