{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "from imutils import paths\n",
    "from collections import defaultdict \n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROSS_VAL_DIR = '../data/cross_validation'\n",
    "MODEL_SAVE_DIR = '../trained_models'\n",
    "N_EPOCHS = 5\n",
    "FOLD = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "MODEL_NAME = 'resnet18'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Resnet_18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet18_model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: tuple = (224, 224, 3),\n",
    "                 hidden_size: int = 64,\n",
    "                 dropout: float = 0.5,\n",
    "                 num_classes: int = 3,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize a new network\n",
    "        \n",
    "        Inputs: \n",
    "        - input_size: Tuple, size of input data\n",
    "        - hidden_size: Integer, number of units to use in hidden layer\n",
    "        - dropout: Float, dropout coefficient\n",
    "        - num_classes: Integer, number of classes\n",
    "        \"\"\"\n",
    "        \n",
    "        super(resnet18_model, self).__init__()\n",
    "        \n",
    "        # Use GPU if available\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # load the resnet18 network\n",
    "        self.model = models.resnet18(pretrained=True).to(device)\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])\n",
    "\n",
    "        # freeze weights of base model except last couple layers\n",
    "        last_frozen = 56\n",
    "        count = 0\n",
    "        for param in self.model.parameters():\n",
    "            count += 1\n",
    "            if count < last_frozen:\n",
    "                param.requires_grad = False\n",
    "            \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pocovid Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PocovidDataset(Dataset):\n",
    "    \"\"\"Subclass of Dataset for POCOVID-Net data\"\"\"\n",
    "  \n",
    "    def __init__(self, data_path_info, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          data_path_info (dict): Dictionary containing the paths and labels for images\n",
    "          transform (callable, optional): Optional transform to be applied\n",
    "              on a sample.\n",
    "        \"\"\"\n",
    "        self.__transform = transform\n",
    "        \n",
    "        self.__covid_class = 0\n",
    "        self.__pneu_class = 1\n",
    "        self.__regular_class = 2\n",
    "\n",
    "        covid_items = []\n",
    "        pneu_items = []\n",
    "        regular_items = []\n",
    "\n",
    "        for i in range(len(data_path_info['path_list'])):\n",
    "            if(data_path_info['label_list'][i] == 'covid'):\n",
    "                covid_items.append(data_path_info['path_list'][i])\n",
    "            elif(data_path_info['label_list'][i] == 'pneumonia'):\n",
    "                pneu_items.append(data_path_info['path_list'][i])\n",
    "            else:\n",
    "                regular_items.append(data_path_info['path_list'][i])\n",
    "\n",
    "        num_covid = 0\n",
    "        num_pneu = 0\n",
    "        num_regular = 0 \n",
    "        \n",
    "        self.__img_info = []\n",
    "        for covid_filename in covid_items: \n",
    "            image = Image.open(covid_filename)\n",
    "            to_tensor_tsfm = ToTensor()\n",
    "            im_tensor = to_tensor_tsfm(image)\n",
    "            if im_tensor.shape[0] == 3:\n",
    "                self.__img_info.append((covid_filename,self.__covid_class))\n",
    "                num_covid += 1\n",
    "            \n",
    "        for pneu_filename in pneu_items:\n",
    "            image = Image.open(pneu_filename)\n",
    "            to_tensor_tsfm = ToTensor()\n",
    "            im_tensor = to_tensor_tsfm(image)\n",
    "            if im_tensor.shape[0] == 3:\n",
    "                self.__img_info.append((pneu_filename,self.__pneu_class))\n",
    "                num_pneu += 1\n",
    "                \n",
    "        for regular_filename in regular_items:\n",
    "            image = Image.open(regular_filename)\n",
    "            to_tensor_tsfm = ToTensor()\n",
    "            im_tensor = to_tensor_tsfm(image)\n",
    "            if im_tensor.shape[0] == 3:\n",
    "                self.__img_info.append((regular_filename,self.__regular_class)) \n",
    "                num_regular += 1\n",
    "\n",
    "        self.__transform = transform\n",
    "        self.__num_images = num_covid + num_pneu + num_regular\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.__num_images\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        img_name, img_class = self.__img_info[idx]\n",
    "        image = Image.open(img_name)\n",
    "        sample = [image, img_class]\n",
    "\n",
    "        if self.__transform:\n",
    "            sample = [self.__transform(image), img_class]\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def get_covid_class_idx(self):\n",
    "        return self.__covid_class\n",
    "    \n",
    "    def get_pneu_class_idx(self):\n",
    "        return self.__pneu_class\n",
    "    \n",
    "    def get_regular_class_idx(self):\n",
    "        return self.__regular_class\n",
    "    \n",
    "    def get_class_map(self):\n",
    "        class_map = {self.get_covid_class_idx() : 'covid',\n",
    "            self.get_pneu_class_idx() : 'pneumonia',\n",
    "            self.get_regular_class_idx() : 'regular'}\n",
    "        return class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Training Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \n",
    "    def __init__(self, model_name=MODEL_NAME, lr=LR, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, \n",
    "                 image_width=IMG_WIDTH, image_height=IMG_HEIGHT, cross_val_dir=CROSS_VAL_DIR,\n",
    "                model_save_dir=MODEL_SAVE_DIR, fold=FOLD):\n",
    "        \n",
    "        if(model_name=='vgg16'):\n",
    "            self.model = VGG16_model().to(device)\n",
    "        elif(model_name=='resnet18'):\n",
    "            self.model = resnet18_model().to(device)\n",
    "        else:\n",
    "            print('Select models from the following:\\n 1) vgg16\\n 2) resnet50')\n",
    "                    \n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        self.cross_val_dir = cross_val_dir\n",
    "        \n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
    "        self.optimizer = optim.Adam(params = self.model.parameters(), lr=self.lr) #experiment with weigth_decay\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, 1, gamma=0.95) # use scheduler\n",
    "        \n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.train_loader = None\n",
    "        self.test_loader = None\n",
    "        \n",
    "        self.classes = None\n",
    "        self.class_map = None\n",
    "        \n",
    "        \n",
    "    def get_train_test_info(self):\n",
    "        \"\"\"\n",
    "        Get information dictionaries for train and test data\n",
    "        \"\"\"\n",
    "    \n",
    "        imagePaths = list(paths.list_images(self.cross_val_dir))\n",
    "\n",
    "        train_path_info = defaultdict(list)\n",
    "        test_path_info = defaultdict(list)\n",
    "\n",
    "        for imagePath in imagePaths:\n",
    "            path_parts = imagePath.split(os.path.sep)\n",
    "            fold_number = path_parts[-3][-1]\n",
    "            label = path_parts[-2]\n",
    "            if(fold_number==str(self.fold)):\n",
    "                test_path_info['path_list'].append(imagePath)\n",
    "                test_path_info['label_list'].append(label)\n",
    "            else:\n",
    "                train_path_info['path_list'].append(imagePath)\n",
    "                train_path_info['label_list'].append(label)\n",
    "\n",
    "        return train_path_info, test_path_info\n",
    "    \n",
    "    \n",
    "    def get_train_test_loaders(self, num_workers=2):\n",
    "        \n",
    "        \"\"\"\n",
    "        Get the train and test data according to the fold\n",
    "        \"\"\"\n",
    "        \n",
    "        train_path_info, test_path_info = self.get_train_test_info()\n",
    "\n",
    "        train_transform = transforms.Compose([transforms.Resize((self.image_width, self.image_height)),\n",
    "                                           transforms.RandomAffine(10,translate=(0.1,0.1)),\n",
    "                                           transforms.ToTensor()])\n",
    "\n",
    "        test_transform = transforms.Compose([transforms.Resize((self.image_width, self.image_height)),\n",
    "                                           transforms.ToTensor()])\n",
    "\n",
    "        trainset = PocovidDataset(train_path_info, transform = train_transform)\n",
    "        testset = PocovidDataset(test_path_info, transform = test_transform)\n",
    "        \n",
    "        self.class_map = trainset.get_class_map()\n",
    "        self.classes = [self.class_map[key] for key in sorted(self.class_map)]\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, num_workers=num_workers, shuffle=True,\n",
    "                                          batch_size=self.batch_size, drop_last=True)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(testset, num_workers=num_workers, shuffle=True,\n",
    "                                        batch_size=self.batch_size)\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "    \n",
    "    def train(self, iterator):\n",
    "        \"\"\"\n",
    "        The train function\n",
    "        \"\"\"\n",
    "    \n",
    "        self.model.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(inputs)\n",
    "\n",
    "            loss = self.criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        return epoch_loss / len(iterator)\n",
    "\n",
    "    def evaluate(self, iterator):\n",
    "        \"\"\"\n",
    "        The eval function\n",
    "        \"\"\"\n",
    "    \n",
    "        self.model.eval()\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        with torch.no_grad():    \n",
    "            for i, batch in enumerate(iterator):    \n",
    "\n",
    "                inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "        return epoch_loss / len(iterator)\n",
    "    \n",
    "    def epoch_time(self, start_time, end_time):\n",
    "        \"\"\"\n",
    "        The utility function to measure the time taken by an epoch to run\n",
    "        \"\"\"\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "        return elapsed_mins, elapsed_secs\n",
    "    \n",
    "    def training(self):\n",
    "        \"\"\"\n",
    "        The training function which does the training by calling train and eval functions\n",
    "        \"\"\"\n",
    "    \n",
    "        best_valid_loss = np.inf\n",
    "        c = 0\n",
    "        \n",
    "        self.train_loader, self.test_loader = self.get_train_test_loaders()\n",
    "        \n",
    "        # Create the model save dir if it already doesn't exist\n",
    "        if not os.path.exists(self.model_save_dir):\n",
    "            os.makedirs(self.model_save_dir)\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "\n",
    "            print(f'Epoch: {epoch+1:02}')\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            train_loss = self.train(self.train_loader)\n",
    "            valid_loss = self.evaluate(self.test_loader)\n",
    "\n",
    "            epoch_mins, epoch_secs = self.epoch_time(start_time, time.time())\n",
    "\n",
    "            c+=1\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save(self.model.state_dict(), os.path.join(self.model_save_dir, '{}_trained.pt'.format(self.model_name)))\n",
    "                c=0\n",
    "\n",
    "            if c>4:\n",
    "                #decrease lr if loss does not decrease after 5 steps\n",
    "                self.scheduler.step()\n",
    "                c=0\n",
    "\n",
    "            print(f'Time: {epoch_mins}m {epoch_secs}s') \n",
    "            print(f'Train Loss: {train_loss:.3f}')\n",
    "            print(f'Val   Loss: {valid_loss:.3f}')\n",
    "            print('-'*100)\n",
    "        print(best_valid_loss)\n",
    "        \n",
    "    def evaluate_model(self, iterator=None, proba=False, one_batch=False):\n",
    "        \n",
    "        if iterator is None:\n",
    "            iterator = self.test_loader\n",
    "    \n",
    "        self.model.eval()\n",
    "\n",
    "        images = []\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        pred_probs = []\n",
    "\n",
    "        with torch.no_grad():    \n",
    "            for i, batch in enumerate(iterator):    \n",
    "\n",
    "                inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                y_prob = F.softmax(outputs, dim = -1)\n",
    "\n",
    "                top_preds = y_prob.argmax(1, keepdim = True)\n",
    "\n",
    "                images.append(inputs.to(device))\n",
    "                true_labels.append(labels.to(device))\n",
    "                pred_labels.append(top_preds.to(device))\n",
    "                pred_probs.append(y_prob.to(device))\n",
    "\n",
    "                if(one_batch):\n",
    "                    break\n",
    "\n",
    "        images = torch.cat(images, dim=0)\n",
    "        true_labels = torch.cat(true_labels, dim=0)\n",
    "        pred_labels = torch.cat(pred_labels, dim=0)\n",
    "        pred_probs = torch.cat(pred_probs, dim=0)\n",
    "\n",
    "        if(proba):\n",
    "            return images, true_labels, pred_labels, pred_probs\n",
    "\n",
    "        return images, true_labels, pred_labels\n",
    "    \n",
    "    def visualize_test_samples(self):\n",
    "    \n",
    "        images, true_labels, pred_labels, pred_probs = self.evaluate_model(proba=True, one_batch=True)\n",
    "\n",
    "        true_labels = true_labels.cpu().numpy()\n",
    "        pred_labels = pred_labels.cpu().numpy()\n",
    "        pred_probs = pred_probs.cpu().numpy()\n",
    "\n",
    "\n",
    "        rows = int(np.sqrt(len(images)))\n",
    "        cols = int(np.sqrt(len(images)))\n",
    "\n",
    "        fig = plt.figure(figsize = (25, 20))\n",
    "\n",
    "        for i in range(rows*cols):\n",
    "\n",
    "            ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "            image, true_label, pred_label, pred_prob = images[i], true_labels[i], pred_labels[i], pred_probs[i]\n",
    "            image = image.permute(1, 2, 0)\n",
    "            ax.imshow(image.cpu().numpy())\n",
    "            ax.set_title(f'true label: {self.class_map[true_label]}\\n' \\\n",
    "                        f'pred label: {self.class_map[pred_label[0]]} (Prob: {max(pred_prob):.3f})',\n",
    "                        color = ('green' if true_label==pred_label[0] else 'red'))\n",
    "            ax.axis('off')\n",
    "\n",
    "        fig.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def start_training(self):\n",
    "        \"\"\"\n",
    "        To start trainig, evaluate the trained model and print the metrics\n",
    "        \"\"\"\n",
    "        self.training()\n",
    "        \n",
    "        images, true_labels, pred_labels, pred_probs = self.evaluate_model(proba=True)\n",
    "        \n",
    "        metrics = Metrics(images, true_labels, pred_labels, pred_probs, self.classes)\n",
    "\n",
    "        cm = metrics.get_confusion_matrix()\n",
    "        print('The confusion matrix is:\\n', cm)\n",
    "        \n",
    "        cr = metrics.get_classification_report()\n",
    "        print('The classification report is:\\n', cr)\n",
    "        \n",
    "        print('ROC Curves:')\n",
    "        metrics.get_roc_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Trained Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainedModel():\n",
    "    \n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        \"\"\"\n",
    "        To get the details of the pre-trained model\n",
    "        \"\"\"\n",
    "        trainer = Trainer(model_name=model_name)\n",
    "        self.model = trainer.model\n",
    "        self.model_save_dir = trainer.model_save_dir\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def loadModel(self):\n",
    "        \"\"\"\n",
    "        To load the pre trained model\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.model_save_dir, '{}_trained.pt'.format(self.model_name)), map_location=torch.device(device)))\n",
    "        return self.model\n",
    "    \n",
    "    def countParameters(self):\n",
    "        \"\"\"\n",
    "        To get the number of trainable parameters of the model\n",
    "        \"\"\"\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "    \n",
    "    def printModel(self):\n",
    "        \"\"\"\n",
    "        To print the network architecture\n",
    "        \"\"\"\n",
    "        print(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Metrics Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    \n",
    "    def __init__(self, images, true_labels, pred_labels, pred_probs, classes):\n",
    "\n",
    "        self.images = images\n",
    "        self.true_labels = true_labels\n",
    "        self.pred_labels = pred_labels\n",
    "        self.pred_probs = pred_probs\n",
    "        self.classes = classes\n",
    "        \n",
    "    def plot_confusion_matrix(self):\n",
    "        fig = plt.figure(figsize = (10, 10));\n",
    "        ax = fig.add_subplot(1, 1, 1);\n",
    "        cm = self.get_confusion_matrix()\n",
    "        cm = ConfusionMatrixDisplay(cm, display_labels = self.classes);\n",
    "        cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
    "        plt.xticks(rotation = 20)\n",
    "    \n",
    "    def get_confusion_matrix(self):\n",
    "        cm = confusion_matrix(self.true_labels.cpu().numpy(), self.pred_labels.cpu().numpy())\n",
    "        return cm\n",
    "        \n",
    "    def get_classification_report(self):\n",
    "        cr = classification_report(self.true_labels.cpu().numpy(), self.pred_labels.cpu().numpy(), target_names=self.classes)\n",
    "        return cr\n",
    "    \n",
    "    def get_roc_curves(self):\n",
    "        # Based off example from: \n",
    "        # https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "        \n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        y = label_binarize(self.true_labels.cpu().numpy(), classes=[0, 1, 2])\n",
    "        for i in range(len(self.classes)):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y[:, i], self.pred_probs.cpu().numpy()[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "            \n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), self.pred_probs.cpu().numpy().ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        # First aggregate all false positive rates\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(self.classes))]))\n",
    "\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(len(self.classes)):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= len(self.classes)\n",
    "\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        # Plot all ROC curves\n",
    "        plt.figure()\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                     ''.format(roc_auc[\"micro\"]),\n",
    "                 color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                 label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                     ''.format(roc_auc[\"macro\"]),\n",
    "                 color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "        \n",
    "        for i, color in zip(range(len(self.classes)), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                     label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                     ''.format(self.classes[i], roc_auc[i]))\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "trainer.start_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch sample input\n",
    "Don't augment this data becuase we want to see how the neural network behaves with real data as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_data, test_path_data = trainer.get_train_test_info()\n",
    "vis_transform = transforms.Compose([transforms.Resize((trainer.image_width, trainer.image_height)),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "visset = PocovidDataset(test_path_data, transform = vis_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(visset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_idx = visset.get_covid_class_idx();\n",
    "pneu_idx = visset.get_pneu_class_idx();\n",
    "regular_idx = visset.get_regular_class_idx();\n",
    "lbl_map = {covid_idx:\"COVID\",pneu_idx:\"Pneumonia\",regular_idx:\"Regular\"} \n",
    "\n",
    "# based on show_landmarks_batch() in the official PyTorch dataloader tutorial\n",
    "def show_labeled_images_batch(sample_batched):\n",
    "  \"\"\"Show image with class labels for a batch of samples.\"\"\"\n",
    "  images_batch, classes_batch = sample_batched[0], sample_batched[1]\n",
    "  batch_size = len(images_batch)\n",
    "  assert images_batch.size(2) == images_batch.size(3)   # assume images are square\n",
    "  im_width = images_batch.size(2) \n",
    "  grid_border_size = 2\n",
    "\n",
    "  labels = [lbl_map[i.item()] for i in classes_batch]\n",
    "  title_str = 'From left: ' + ', '.join(labels)\n",
    "  plt.title(title_str)\n",
    "  \n",
    "  grid = torchvision.utils.make_grid(images_batch)\n",
    "  plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "  plt.title(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_batch(sample_idx):\n",
    "\n",
    "  for i_batch, sample_batched in enumerate(dataloader):\n",
    "      # observe 4th batch, visualize images, and stop\n",
    "      if i_batch == sample_idx:\n",
    "          plt.figure()\n",
    "\n",
    "          show_labeled_images_batch(sample_batched)\n",
    "          plt.axis('off')\n",
    "          plt.ioff()\n",
    "          plt.show()\n",
    "          return sample_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = get_sample_batch(sample_idx=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"util\")\n",
    "import vizutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images, sample_classes = test_sample[0], test_sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_images[test_batch_idx].detach().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_images.cuda().detach()\n",
    "y = sample_classes.cuda().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = vizutils.compute_saliency_maps(X, y, 3, trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_np = saliency.cpu().numpy()\n",
    "plt.imshow(saliency_np[test_batch_idx], cmap=plt.cm.inferno)\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
