{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "from imutils import paths\n",
    "from collections import defaultdict \n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The VGG_16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16_model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: tuple = (3, 224, 224),\n",
    "                 hidden_size: int = 64,\n",
    "                 dropout: float = 0.5,\n",
    "                 num_classes: int = 3,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize a new network\n",
    "        \n",
    "        Inputs: \n",
    "        - input_size: Tuple, size of input data\n",
    "        - hidden_size: Integer, number of units to use in hidden layer\n",
    "        - dropout: Float, dropout coefficient\n",
    "        - num_classes: Integer, number of classes\n",
    "        \"\"\"\n",
    "        \n",
    "        super(VGG16_model, self).__init__()\n",
    "        \n",
    "        # load the VGG16 network\n",
    "        self.model = models.vgg16(pretrained=True)\n",
    "\n",
    "        # freeze weights of base model except last cnn layer\n",
    "        # model.parameters() does not include max pooling layers\n",
    "        last_frozen = 25\n",
    "        count = 0\n",
    "        for param in self.model.parameters():\n",
    "            count += 1\n",
    "            if count < last_frozen:\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        # Taking only sequential part\n",
    "        self.model = self.model.features\n",
    "    \n",
    "        self.avgpool = nn.AvgPool2d(4)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512, hidden_size)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn(x) \n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pocovid Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PocovidDataset(Dataset):\n",
    "    \"\"\"Subclass of Dataset for POCOVID-Net data\"\"\"\n",
    "  \n",
    "    def __init__(self, data_path_info, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          data_path_info (dict): Dictionary containing the paths and labels for images\n",
    "          transform (callable, optional): Optional transform to be applied\n",
    "              on a sample.\n",
    "        \"\"\"\n",
    "        self.__transform = transform\n",
    "        \n",
    "        self.__covid_class = 0\n",
    "        self.__pneu_class = 1\n",
    "        self.__regular_class = 2\n",
    "\n",
    "        covid_items = []\n",
    "        pneu_items = []\n",
    "        regular_items = []\n",
    "\n",
    "        for i in range(len(data_path_info['path_list'])):\n",
    "            if(data_path_info['label_list'][i] == 'covid'):\n",
    "                covid_items.append(data_path_info['path_list'][i])\n",
    "            elif(data_path_info['label_list'][i] == 'pneumonia'):\n",
    "                pneu_items.append(data_path_info['path_list'][i])\n",
    "            else:\n",
    "                regular_items.append(data_path_info['path_list'][i])\n",
    "\n",
    "        num_covid = 0\n",
    "        num_pneu = 0\n",
    "        num_regular = 0 \n",
    "        \n",
    "        self.__img_info = []\n",
    "        for covid_filename in covid_items: \n",
    "            image = Image.open(covid_filename)\n",
    "            to_tensor_tsfm = ToTensor()\n",
    "            im_tensor = to_tensor_tsfm(image)\n",
    "            if im_tensor.shape[0] == 3:\n",
    "                self.__img_info.append((covid_filename,self.__covid_class))\n",
    "                num_covid += 1\n",
    "            \n",
    "        for pneu_filename in pneu_items:\n",
    "            image = Image.open(pneu_filename)\n",
    "            to_tensor_tsfm = ToTensor()\n",
    "            im_tensor = to_tensor_tsfm(image)\n",
    "            if im_tensor.shape[0] == 3:\n",
    "                self.__img_info.append((pneu_filename,self.__pneu_class))\n",
    "                num_pneu += 1\n",
    "                \n",
    "        for regular_filename in regular_items:\n",
    "            image = Image.open(regular_filename)\n",
    "            to_tensor_tsfm = ToTensor()\n",
    "            im_tensor = to_tensor_tsfm(image)\n",
    "            if im_tensor.shape[0] == 3:\n",
    "                self.__img_info.append((regular_filename,self.__regular_class)) \n",
    "                num_regular += 1\n",
    "\n",
    "        self.__transform = transform\n",
    "        self.__num_images = num_covid + num_pneu + num_regular\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.__num_images\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        img_name, img_class = self.__img_info[idx]\n",
    "        image = Image.open(img_name)\n",
    "        sample = [image, img_class]\n",
    "\n",
    "        if self.__transform:\n",
    "            sample = [self.__transform(image), img_class]\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def get_covid_class_idx(self):\n",
    "        return self.__covid_class\n",
    "    \n",
    "    def get_pneu_class_idx(self):\n",
    "        return self.__pneu_class\n",
    "    \n",
    "    def get_regular_class_idx(self):\n",
    "        return self.__regular_class\n",
    "    \n",
    "    def get_class_map(self):\n",
    "        class_map = {self.get_covid_class_idx() : 'covid',\n",
    "            self.get_pneu_class_idx() : 'pneumonia',\n",
    "            self.get_regular_class_idx() : 'regular'}\n",
    "        return class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### The Trainer Class\n",
    "class Trainer():\n",
    "    \n",
    "    def __init__(self, model_name=MODEL_NAME, lr=LR, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, \n",
    "                 image_width=IMG_WIDTH, image_height=IMG_HEIGHT, cross_val_dir=CROSS_VAL_DIR,\n",
    "                model_save_dir=MODEL_SAVE_DIR, fold=FOLD):\n",
    "        \n",
    "        if(model_name=='vgg16'):\n",
    "            self.model = VGG16_model().to(device)\n",
    "        elif(model_name=='resnet50'):\n",
    "            self.model = RESNET50_model().to(device)\n",
    "        else:\n",
    "            print('Select models from the following:\\n 1) vgg16\\n 2) resnet50')\n",
    "                    \n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        \n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
    "        self.optimizer = optim.Adam(params = self.model.parameters(), lr=self.lr) #experiment with weigth_decay\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, 1, gamma=0.95) # use scheduler\n",
    "        \n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.train_loader = None\n",
    "        self.test_loader = None\n",
    "        \n",
    "        self.classes = None\n",
    "        self.class_map = None\n",
    "        \n",
    "        \n",
    "    def get_train_test_info(self):\n",
    "        \"\"\"\n",
    "        Get information dictionaries for train and test data\n",
    "        \"\"\"\n",
    "    \n",
    "        imagePaths = list(paths.list_images(cross_val_dir))\n",
    "\n",
    "        train_path_info = defaultdict(list)\n",
    "        test_path_info = defaultdict(list)\n",
    "\n",
    "        for imagePath in imagePaths:\n",
    "            path_parts = imagePath.split(os.path.sep)\n",
    "            fold_number = path_parts[-3][-1]\n",
    "            label = path_parts[-2]\n",
    "            if(fold_number==str(self.fold)):\n",
    "                test_path_info['path_list'].append(imagePath)\n",
    "                test_path_info['label_list'].append(label)\n",
    "            else:\n",
    "                train_path_info['path_list'].append(imagePath)\n",
    "                train_path_info['label_list'].append(label)\n",
    "\n",
    "        return train_path_info, test_path_info\n",
    "    \n",
    "    \n",
    "    def get_train_test_loaders(self, num_workers=2):\n",
    "        \n",
    "        \"\"\"\n",
    "        Get the train and test data according to the fold\n",
    "        \"\"\"\n",
    "        \n",
    "        train_path_info, test_path_info = self.get_train_test_info()\n",
    "\n",
    "        train_transform = transforms.Compose([transforms.Resize((self.image_width, self.image_height)),\n",
    "                                           transforms.RandomAffine(10,translate=(0.1,0.1)),\n",
    "                                           transforms.ToTensor()])\n",
    "\n",
    "        test_transform = transforms.Compose([transforms.Resize((self.image_width, self.image_height)),\n",
    "                                           transforms.ToTensor()])\n",
    "\n",
    "        trainset = PocovidDataset(train_path_info, transform = train_transform)\n",
    "        testset = PocovidDataset(test_path_info, transform = test_transform)\n",
    "        \n",
    "        self.class_map = trainset.get_class_map()\n",
    "        self.classes = [self.class_map[key] for key in sorted(self.class_map)]\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, num_workers=num_workers, shuffle=True,\n",
    "                                          batch_size=self.batch_size, drop_last=True)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(testset, num_workers=num_workers, shuffle=True,\n",
    "                                        batch_size=self.batch_size)\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "    \n",
    "    def train(self, iterator):\n",
    "        \"\"\"\n",
    "        The train function\n",
    "        \"\"\"\n",
    "    \n",
    "        self.model.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(inputs)\n",
    "\n",
    "            loss = self.criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        return epoch_loss / len(iterator)\n",
    "\n",
    "    def evaluate(self, iterator):\n",
    "        \"\"\"\n",
    "        The eval function\n",
    "        \"\"\"\n",
    "    \n",
    "        self.model.eval()\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        with torch.no_grad():    \n",
    "            for i, batch in enumerate(iterator):    \n",
    "\n",
    "                inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "        return epoch_loss / len(iterator)\n",
    "    \n",
    "    def epoch_time(self, start_time, end_time):\n",
    "        \"\"\"\n",
    "        The utility function to measure the time taken by an epoch to run\n",
    "        \"\"\"\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "        return elapsed_mins, elapsed_secs\n",
    "    \n",
    "    def training(self):\n",
    "        \"\"\"\n",
    "        The training function which does the training by calling train and eval functions\n",
    "        \"\"\"\n",
    "    \n",
    "        best_valid_loss = np.inf\n",
    "        c = 0\n",
    "        \n",
    "        self.train_loader, self.test_loader = self.get_train_test_loaders()\n",
    "        \n",
    "        # Create the model save dir if it already doesn't exist\n",
    "        if not os.path.exists(self.model_save_dir):\n",
    "            os.makedirs(self.model_save_dir)\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "\n",
    "            print(f'Epoch: {epoch+1:02}')\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            train_loss = self.train(self.train_loader)\n",
    "            valid_loss = self.evaluate(self.test_loader)\n",
    "\n",
    "            epoch_mins, epoch_secs = self.epoch_time(start_time, time.time())\n",
    "\n",
    "            c+=1\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save(self.model.state_dict(), os.path.join(self.model_save_dir, '{}_trained.pt'.format(self.model_name)))\n",
    "                c=0\n",
    "\n",
    "            if c>4:\n",
    "                #decrease lr if loss does not decrease after 5 steps\n",
    "                self.scheduler.step()\n",
    "                c=0\n",
    "\n",
    "            print(f'Time: {epoch_mins}m {epoch_secs}s') \n",
    "            print(f'Train Loss: {train_loss:.3f}')\n",
    "            print(f'Val   Loss: {valid_loss:.3f}')\n",
    "            print('-'*100)\n",
    "        print(best_valid_loss)\n",
    "        \n",
    "    def evaluate_model(self, iterator=self.test_loader, proba=False, one_batch=False):\n",
    "    \n",
    "        self.model.eval()\n",
    "\n",
    "        images = []\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        pred_probs = []\n",
    "\n",
    "        with torch.no_grad():    \n",
    "            for i, batch in enumerate(iterator):    \n",
    "\n",
    "                inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                y_prob = F.softmax(outputs, dim = -1)\n",
    "\n",
    "                top_preds = y_prob.argmax(1, keepdim = True)\n",
    "\n",
    "                images.append(inputs.to(device))\n",
    "                true_labels.append(labels.to(device))\n",
    "                pred_labels.append(top_preds.to(device))\n",
    "                pred_probs.append(y_prob.to(device))\n",
    "\n",
    "                if(one_batch):\n",
    "                    break\n",
    "\n",
    "        images = torch.cat(images, dim=0)\n",
    "        true_labels = torch.cat(true_labels, dim=0)\n",
    "        pred_labels = torch.cat(pred_labels, dim=0)\n",
    "        pred_probs = torch.cat(pred_probs, dim=0)\n",
    "\n",
    "        if(proba):\n",
    "            return images, true_labels, pred_labels, pred_probs\n",
    "\n",
    "        return images, true_labels, pred_labels\n",
    "    \n",
    "    def visualize_test_samples(self):\n",
    "    \n",
    "        images, true_labels, pred_labels, pred_probs = self.evaluate_model(proba=True, one_batch=True)\n",
    "\n",
    "        true_labels = true_labels.cpu().numpy()\n",
    "        pred_labels = pred_labels.cpu().numpy()\n",
    "        pred_probs = pred_probs.cpu().numpy()\n",
    "\n",
    "\n",
    "        rows = int(np.sqrt(len(images)))\n",
    "        cols = int(np.sqrt(len(images)))\n",
    "\n",
    "        fig = plt.figure(figsize = (25, 20))\n",
    "\n",
    "        for i in range(rows*cols):\n",
    "\n",
    "            ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "            image, true_label, pred_label, pred_prob = images[i], true_labels[i], pred_labels[i], pred_probs[i]\n",
    "            image = image.permute(1, 2, 0)\n",
    "            ax.imshow(image.cpu().numpy())\n",
    "            ax.set_title(f'true label: {self.class_map[true_label]}\\n' \\\n",
    "                        f'pred label: {self.class_map[pred_label[0]]} (Prob: {max(pred_prob):.3f})',\n",
    "                        color = ('green' if true_label==pred_label[0] else 'red'))\n",
    "            ax.axis('off')\n",
    "\n",
    "        fig.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def start_training(self):\n",
    "        \"\"\"\n",
    "        To start trainig, evaluate the trained model and print the metrics\n",
    "        \"\"\"\n",
    "        self.training()\n",
    "        \n",
    "        images, true_labels, pred_labels, pred_probs = self.evaluate_model(proba=True)\n",
    "        \n",
    "        metrics = Metrics(images, true_labels, pred_labels, pred_probs, self.classes)\n",
    "\n",
    "        cm = metrics.get_confusion_matrix()\n",
    "        print('The confusion matrix is:\\n', cm)\n",
    "        \n",
    "        cr = metrics.get_classification_report()\n",
    "        print('The classification report is:\\n', cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Trained Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainedModel():\n",
    "    \n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        \"\"\"\n",
    "        To get the details of the pre-trained model\n",
    "        \"\"\"\n",
    "        trainer = Trainer(model_name=model_name)\n",
    "        self.model = trainer.model\n",
    "        self.model_save_dir = trainer.model_save_dir\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def loadModel(self):\n",
    "        \"\"\"\n",
    "        To load the pre trained model\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.model_save_dir, '{}_trained.pt'.format(self.model_name)), map_location=torch.device(device)))\n",
    "        return self.model\n",
    "    \n",
    "    def countParameters(self):\n",
    "        \"\"\"\n",
    "        To get the number of trainable parameters of the model\n",
    "        \"\"\"\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "    \n",
    "    def printModel(self):\n",
    "        \"\"\"\n",
    "        To print the network architecture\n",
    "        \"\"\"\n",
    "        print(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Metrics Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    \n",
    "    def __init__(self, images, true_labels, pred_labels, pred_probs, classes):\n",
    "\n",
    "        self.images = images\n",
    "        self.true_labels = true_labels\n",
    "        self.pred_labels = pred_labels\n",
    "        seld.pred_probs = pred_probs\n",
    "        self.classes = classes\n",
    "        \n",
    "    def plot_confusion_matrix(self):\n",
    "        fig = plt.figure(figsize = (10, 10));\n",
    "        ax = fig.add_subplot(1, 1, 1);\n",
    "        cm = self.get_confusion_matrix()\n",
    "        cm = ConfusionMatrixDisplay(cm, display_labels = self.classes);\n",
    "        cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
    "        plt.xticks(rotation = 20)\n",
    "    \n",
    "    def get_confusion_matrix(self)\n",
    "        cm = confusion_matrix(self.true_labels.cpu().numpy(), self.pred_labels.cpu().numpy())\n",
    "        \n",
    "    def get_classification_report(self):\n",
    "        cr = classification_report(self.true_labels.cpu().numpy(), self.pred_labels.cpu().numpy(), target_names=self.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROSS_VAL_DIR = '../data/cross_validation'\n",
    "MODEL_SAVE_DIR = '../trained_models'\n",
    "N_EPOCHS = 5\n",
    "FOLD = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "MODEL_NAME = 'vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "trainer = Trainer()\n",
    "trainer.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo:\n",
    "# 1) Implement ROC graph with confidence values (J)\n",
    "# 2) Hypertune the paramaters for best results (N)\n",
    "# 3) Implement voting classifier from all 5 folds using 5 models (A)\n",
    "# 4) Add code for early stopping (A)\n",
    "# 5) Do visualization stuff (N)\n",
    "# 6) Refactor all code and make the training and testing scripts with args (A) --> Done\n",
    "# 7) Finalize this notebook with all code included (A) --> 90% Done\n",
    "# 8) Implement the flask api (A)\n",
    "# 9) Test the script and prepare a notebook for Resnet model (J)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
